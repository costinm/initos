#!/bin/bash

# Functions to run various things at 'pod' startup ( or docker image, VM)
# Expects tini (for zombies).
# Detects if vncserver is installed - and starts it if it is. Same for CRD.
# 

APPS_DIR=/x/sync/app

set -eo pipefail

# set -u is for unbound variables 

USERNAME=${USERNAME:-build}
export REMOTE_DESKTOP=${REMOTE_DESKTOP:-crd}

function start_x() {
  if [ -f /etc/init.d/dbus ]; then
    /etc/init.d/dbus start
  fi
  if [ -f /etc/init.d/x11-common ]; then
    /etc/init.d/x11-common start
  fi

  if [ -f /etc/init.d/chrome-remote-desktop ]; then
    usermod -a -G chrome-remote-desktop ${USERNAME} || true
    /etc/init.d/chrome-remote-desktop start
  elif [ -f /usr/bin/kasmvncserver ]; then
    if [ -f /dev/dri/renderD128  ] ; then
     sudo -u ${USERNAME} vncserver -hw3d -drinode /dev/dri/renderD128
    else
      sudo -u ${USERNAME} vncserver
    fi 
  fi
}

launch_xvfb() {
    # https://medium.com/dot-debug/running-chrome-in-a-docker-container-a55e7f4da4a8
    # Set defaults if the user did not specify envs.
    export DISPLAY=${XVFB_DISPLAY:-:1}
    local screen=${XVFB_SCREEN:-0}
    local resolution=${XVFB_RESOLUTION:-1280x1024x24}
    local timeout=${XVFB_TIMEOUT:-5}

    # Start and wait for either Xvfb to be fully up,
    # or we hit the timeout.
    Xvfb ${DISPLAY} -screen ${screen} ${resolution} &
    local loopCount=0
    until xdpyinfo -display ${DISPLAY} > /dev/null 2>&1
    do
        loopCount=$((loopCount+1))
        sleep 1
        if [ ${loopCount} -gt ${timeout} ]
        then
            echo "[ERROR] xvfb failed to start."
            exit 1
        fi
    done
}

# This can export any existing DISPLAY - and is broadly supported,
# but not fastest.
run_vnc_server() {
    local passwordArgument='-nopw'
    if [ -n "${VNC_SERVER_PASSWORD}" ]
    then
        local passwordFilePath="${HOME}/x11vnc.pass"
        if ! x11vnc -storepasswd "${VNC_SERVER_PASSWORD}" "${passwordFilePath}"
        then
            echo "[ERROR] Failed to store x11vnc password."
            exit 1
        fi
        passwordArgument=-"-rfbauth ${passwordFilePath}"
        echo "[INFO] The VNC server will ask for a password."
    else
        echo "[WARN] The VNC server will NOT ask for a password."
    fi
    x11vnc -display ${DISPLAY} -forever ${passwordArgument} &
    wait $!
}


function start_chrome_in_docker() {
  # CHROME_CONFIG_HOME env variable is set in CRD to create a separate env.
  # CHROME_USER_DATA_DIR is set to ~/.config/chrome-remote-desktop/chrome-profile (if found)

  # --enable-logging=stderr --disable-gpu -v=1
  # --disable-setuid-sandbox --disable-seccomp --disable-namespace-sandbox --no-sandbox  --disable-notifications --disable-seccomp-filter-sandbox
  google-chrome   --disable-dev-shm-usage
}

# Add a custom user - with PID, PGID, PUSERNAME ('pod').
function add_main_user() {
  local u=${USERNAME:-build}
  local h=${HOME:-/x/home/${u}}

  userdel build

  echo Adding $u with $h and $USERID

  useradd -u ${USERID:-1000} -g users -G users -s /bin/bash \
         -d ${h} ${USERNAME}

  usermod -p '*' ${USERNAME}

  chown ${u} /home /work

  # rm -rf /work && ln -s /x/work /work

  usermod -a -G chrome-remote-desktop ${u} || true
  usermod -a -G docker ${u} || true
  usermod -a -G kvm ${u} || true
  usermod -a -G video ${u} || true
  usermod -a -G render ${u} || true

  # access to /etc/ssl/private
  usermod -a -G ssl-certs ${u} || true

  echo "${u} ALL=NOPASSWD: ALL" >> /etc/sudoers

  chmod 4755 /x/sync/app/chrome/chrome-sandbox || true
}


function start_as_root() {
  export USERNAME=${USERNAME:-build}
  
  echo PATH=$PATH

  if [ "$USERNAME" == "costin" ]; then 
    # This is for costin16 with encrypted chrome pass...
    cp /home/${USERNAME}/.ssh/machine-id /etc/machine-id
  fi

  # Problems with chrome remote desktop
  rm -f /usr/local/bin/run-parts || true 

  busybox syslogd -C1024

  # Base image should have build user, as UID 1000
  id ${USERNAME} ||     add_main_user
  
  if [ -f /var/run/docker.sock ]; then
    echo Detected host docker - adding user
    groupadd -g 110 docker-host
    usermod -a -G docker-host ${USERNAME} || true
    usermod -a -G docker-host build || true
    usermod -a -G docker ${USERNAME} || true
    usermod -a -G docker build || true
  elif [ -f /usr/bin/dockerd ]; then
    # Available in the Istio base image
    echo Detected docerkd - start
    usermod -a -G docker ${USERNAME} || true
    usermod -a -G docker build || true
    /etc/init.d/docker start 
    # dockerd &
  fi

  # In the UI the env is reset - need to source this to get K8S address if running in K8S
  env  > /tmp/.startup.env

  # Home is part of docker image, work is persistent.
  #ln -s /work/.config ${HOME}

  chown ${USERNAME} /work

  echo "Starting X"

  start_x

  echo "Starting custom username scripts"
  if [ -f /x/start.sh ]; then
     sudo -u $USERNAME /x/start.sh &
  fi

  if [ -f /x/home/${USERNAME}/.onstart ]; then
     sudo -u $USERNAME /x/home/${USERNAME}/.onstart &
  fi
}

# This seems to work without any root.
function start_as_user() {
  busybox syslogd -C1024
  
  # dbus, crd require root - but we can start kvnc as user.
  vncserver
}

function pod() {
  if [ $(id -u) == 0 ]; then 
    start_as_root
  else 
    start_as_user
  fi

  exec sleep infinity
}

if [ -z ${1+x} ] ; then
  echo Starting default: use "pod" $*
  pod
else
  C=${1}
  shift
  $C $*
fi
